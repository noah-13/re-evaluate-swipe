{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN0zpK-XC2pr",
        "outputId": "53b9aa82-5a17-415a-dd39-dd920507e558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     SARI       FKGL  REFEREE_SCORE  SALSA_REFERENCE_FREE  \\\n",
            "ACCESS           0.387576  10.413900      -0.184373             48.510300   \n",
            "KEEP-IT-SIMPLE   0.339022   8.684647       0.511984             65.785754   \n",
            "SWIPE-V5         0.477764   7.707676       0.464713             64.892294   \n",
            "SWIPE-V5-CLEAN   0.455523   8.236722       0.449690             62.072245   \n",
            "GPT3             0.351999   9.470332       0.489155             63.584523   \n",
            "BARTL-WIKILARGE  0.378713   9.716823       0.162640             56.530410   \n",
            "REFERENCE             NaN   8.842739       0.317441             63.688621   \n",
            "\n",
            "                 QUESTEVAL_REFERENCE_BASED  QUESTEVAL_REFERENCE_FREE  \\\n",
            "ACCESS                            0.561528                  0.636953   \n",
            "KEEP-IT-SIMPLE                    0.476347                  0.541861   \n",
            "SWIPE-V5                          0.593995                  0.622487   \n",
            "SWIPE-V5-CLEAN                    0.591827                  0.633329   \n",
            "GPT3                              0.538582                  0.596306   \n",
            "BARTL-WIKILARGE                   0.526175                  0.591801   \n",
            "REFERENCE                              NaN                  0.625706   \n",
            "\n",
            "                 SUMMACZS  SUMMACCONV  \n",
            "ACCESS           0.720100    0.690816  \n",
            "KEEP-IT-SIMPLE   0.087301    0.374115  \n",
            "SWIPE-V5         0.550814    0.657966  \n",
            "SWIPE-V5-CLEAN   0.650206    0.725805  \n",
            "GPT3             0.373833    0.441591  \n",
            "BARTL-WIKILARGE  0.489440    0.595237  \n",
            "REFERENCE        0.476547    0.576414  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-98f1bf5ebf1f>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = pd.to_numeric(df[col], errors='coerce')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df1 = pd.read_csv(\"data/summac.csv\")\n",
        "df2 = pd.read_csv(\"data/referee.csv\")\n",
        "df3 = pd.read_csv(\"data/questeval.csv\", encoding=\"ISO-8859-1\")\n",
        "df4 = pd.read_csv(\"data/salsa.csv\")\n",
        "\n",
        "\n",
        "\n",
        "merged_df = pd.concat([df1, df2, df3, df4], axis=1)\n",
        "\n",
        "\n",
        "df = merged_df.loc[:, ~merged_df.columns.duplicated()]\n",
        "\n",
        "# Identify all columns related to model evaluation\n",
        "model_prefixes = [\"access\", \"keep_it_simple\", \"swipe_v5\", \"swipe_v5_clean\", \"gpt3\", \"bartl_wikilarge\"]\n",
        "metric_names = [\"sari\", \"fkgl\", \"referee_score\", \"salsa_reference_free\", \"questeval_reference_based\",\n",
        "                \"questeval_reference_free\", \"SummaCZS\", \"SummaCConv\"]\n",
        "\n",
        "# Generate the list of all metric columns\n",
        "numeric_columns = [f\"{metric}_{prefix}\" for prefix in model_prefixes for metric in metric_names]\n",
        "\n",
        "# Add reference-related columns\n",
        "numeric_columns += [\"fkgl_reference\", \"referee_score_reference\", \"salsa_reference_free_reference\",\n",
        "                    \"questeval_reference_free_reference\", \"SummaCZS_reference\", \"SummaCConv_reference\"]\n",
        "\n",
        "# Convert all relevant columns to numeric\n",
        "for col in numeric_columns:\n",
        "    if col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Extract models dynamically\n",
        "models = {}\n",
        "\n",
        "for prefix in model_prefixes:\n",
        "    model_name = prefix.upper().replace(\"_\", \"-\")\n",
        "    model_metrics = {}\n",
        "\n",
        "    for metric in metric_names:\n",
        "        column_name = f\"{metric}_{prefix}\"\n",
        "        if column_name in df.columns:\n",
        "            model_metrics[metric.upper()] = df[column_name].mean()  # Compute mean score\n",
        "\n",
        "    models[model_name] = model_metrics\n",
        "\n",
        "# Add Reference model metrics\n",
        "reference_metrics = {\n",
        "    \"SARI\": None,\n",
        "    \"FKGL\": df[\"fkgl_reference\"].mean() if \"fkgl_reference\" in df.columns else None,\n",
        "    \"REFEREE_SCORE\": df[\"referee_score_reference\"].mean() if \"referee_score_reference\" in df.columns else None,\n",
        "    \"SALSA_REFERENCE_FREE\": df[\"salsa_reference_free_reference\"].mean() if \"salsa_reference_free_reference\" in df.columns else None,\n",
        "    \"QUESTEVAL_REFERENCE_BASED\": None,\n",
        "    \"QUESTEVAL_REFERENCE_FREE\": df[\"questeval_reference_free_reference\"].mean() if \"questeval_reference_free_reference\" in df.columns else None,\n",
        "    \"SUMMACZS\": df[\"SummaCZS_reference\"].mean() if \"SummaCZS_reference\" in df.columns else None,\n",
        "    \"SUMMACCONV\": df[\"SummaCConv_reference\"].mean() if \"SummaCConv_reference\" in df.columns else None,\n",
        "}\n",
        "models[\"REFERENCE\"] = reference_metrics\n",
        "\n",
        "# Convert to DataFrame and display results\n",
        "results_df = pd.DataFrame(models).T\n",
        "print(results_df)\n",
        "\n",
        "# Save to CSV\n",
        "results_df.to_csv(\"data/model_evaluation_results.csv\", index=True)\n",
        "\n",
        "\n"
      ]
    }
  ]
}